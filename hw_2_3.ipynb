{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from sklearn.model_selection import KFold, cross_val_score,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_target(df,name):\n",
    "    df_1 = df.copy()\n",
    "    d = { j:(i+1) for i,j in enumerate(iris_data['Species'].unique())}\n",
    "    df_1[name] = df_1[name].map(d)\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation_classif_multi_n(X: pd.DataFrame,\n",
    "                          y: pd.Series,\n",
    "                          estimator: object,\n",
    "                          metric: callable,\n",
    "                          cv_strategy,\n",
    "                          params,print_is = True):\n",
    "   \n",
    "    \n",
    "    estimators, fold_train_scores, fold_valid_scores = [], [], []\n",
    "    oof_predictions = np.zeros((X.shape[0],y.shape[1]))   \n",
    "\n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y)):\n",
    "        x_train, x_valid = X[train_idx], X[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        estimator.fit(x_train, y_train,**params) \n",
    "\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "        y_train_pred = estimator.predict(x_train)\n",
    "        \n",
    "        \n",
    "        fold_train_scores.append(metric(y_train, y_train_pred,multi_class = 'ovr'))\n",
    "        fold_valid_scores.append(metric(y_valid, y_valid_pred,multi_class = 'ovr'))\n",
    "        oof_predictions[valid_idx] = y_valid_pred\n",
    "\n",
    "        msg = (\n",
    "            f\"Fold: {fold_number+1}, train-observations = {len(train_idx)}, \"\n",
    "            f\"valid-observations = {len(valid_idx)}\\n\"\n",
    "            f\"train-score = {round(fold_train_scores[fold_number], 4)}, \"\n",
    "            f\"valid-score = {round(fold_valid_scores[fold_number], 4)}\" \n",
    "        )\n",
    "        if print_is:\n",
    "            print(msg)\n",
    "            print(\"=\"*69)\n",
    "        estimators.append(estimator)\n",
    "    oof_score = metric(y, oof_predictions,multi_class = 'ovr')\n",
    "    if print_is:\n",
    "        print(f\"CV-results train: {round(np.mean(fold_train_scores), 4)} +/- {round(np.std(fold_train_scores), 3)}\")\n",
    "        print(f\"CV-results valid: {round(np.mean(fold_valid_scores), 4)} +/- {round(np.std(fold_valid_scores), 3)}\")\n",
    "        print(f\"OOF-score = {round(oof_score, 4)}\")\n",
    "\n",
    "    return estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_target(train,feature,target):\n",
    "    d = train[train[target]==1].groupby(feature).size()/len(train)*100\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_one_hot(layer):\n",
    "    arr = np.argmax(layer,axis=1)+1\n",
    "    return arr.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Ownership</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Years in current job</th>\n",
       "      <th>Tax Liens</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Term</th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Monthly Debt</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Credit Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Own Home</td>\n",
       "      <td>482087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>685960.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>47386.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Own Home</td>\n",
       "      <td>1025487.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1181730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Long Term</td>\n",
       "      <td>264968.0</td>\n",
       "      <td>394972.0</td>\n",
       "      <td>18373.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>751412.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1182434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>308389.0</td>\n",
       "      <td>13651.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Own Home</td>\n",
       "      <td>805068.0</td>\n",
       "      <td>6 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>147400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>121396.0</td>\n",
       "      <td>95855.0</td>\n",
       "      <td>11338.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rent</td>\n",
       "      <td>776264.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>385836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>125840.0</td>\n",
       "      <td>93309.0</td>\n",
       "      <td>7180.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>Rent</td>\n",
       "      <td>402192.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>107866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>129360.0</td>\n",
       "      <td>73492.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>1533984.0</td>\n",
       "      <td>1 year</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>686312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Long Term</td>\n",
       "      <td>444048.0</td>\n",
       "      <td>456399.0</td>\n",
       "      <td>12783.0</td>\n",
       "      <td>7410.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>Rent</td>\n",
       "      <td>1878910.0</td>\n",
       "      <td>6 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1778920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>buy a car</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>477812.0</td>\n",
       "      <td>12479.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1141250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>615274.0</td>\n",
       "      <td>476064.0</td>\n",
       "      <td>37118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>Rent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>480832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>26928.0</td>\n",
       "      <td>288192.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Home Ownership  Annual Income Years in current job  Tax Liens  \\\n",
       "0          Own Home       482087.0                  NaN        0.0   \n",
       "1          Own Home      1025487.0            10+ years        0.0   \n",
       "2     Home Mortgage       751412.0              8 years        0.0   \n",
       "3          Own Home       805068.0              6 years        0.0   \n",
       "4              Rent       776264.0              8 years        0.0   \n",
       "...             ...            ...                  ...        ...   \n",
       "7495           Rent       402192.0             < 1 year        0.0   \n",
       "7496  Home Mortgage      1533984.0               1 year        0.0   \n",
       "7497           Rent      1878910.0              6 years        0.0   \n",
       "7498  Home Mortgage            NaN                  NaN        0.0   \n",
       "7499           Rent            NaN              4 years        0.0   \n",
       "\n",
       "      Number of Open Accounts  Years of Credit History  Maximum Open Credit  \\\n",
       "0                        11.0                     26.3             685960.0   \n",
       "1                        15.0                     15.3            1181730.0   \n",
       "2                        11.0                     35.0            1182434.0   \n",
       "3                         8.0                     22.5             147400.0   \n",
       "4                        13.0                     13.6             385836.0   \n",
       "...                       ...                      ...                  ...   \n",
       "7495                      3.0                      8.5             107866.0   \n",
       "7496                     10.0                     26.5             686312.0   \n",
       "7497                     12.0                     32.1            1778920.0   \n",
       "7498                     21.0                     26.5            1141250.0   \n",
       "7499                      8.0                      9.4             480832.0   \n",
       "\n",
       "      Number of Credit Problems  Months since last delinquent  Bankruptcies  \\\n",
       "0                           1.0                           NaN           1.0   \n",
       "1                           0.0                           NaN           0.0   \n",
       "2                           0.0                           NaN           0.0   \n",
       "3                           1.0                           NaN           1.0   \n",
       "4                           1.0                           NaN           0.0   \n",
       "...                         ...                           ...           ...   \n",
       "7495                        0.0                           NaN           0.0   \n",
       "7496                        0.0                          43.0           0.0   \n",
       "7497                        0.0                           NaN           0.0   \n",
       "7498                        0.0                           NaN           0.0   \n",
       "7499                        0.0                           NaN           0.0   \n",
       "\n",
       "                 Purpose        Term  Current Loan Amount  \\\n",
       "0     debt consolidation  Short Term           99999999.0   \n",
       "1     debt consolidation   Long Term             264968.0   \n",
       "2     debt consolidation  Short Term           99999999.0   \n",
       "3     debt consolidation  Short Term             121396.0   \n",
       "4     debt consolidation  Short Term             125840.0   \n",
       "...                  ...         ...                  ...   \n",
       "7495               other  Short Term             129360.0   \n",
       "7496  debt consolidation   Long Term             444048.0   \n",
       "7497           buy a car  Short Term           99999999.0   \n",
       "7498  debt consolidation  Short Term             615274.0   \n",
       "7499  debt consolidation  Short Term              26928.0   \n",
       "\n",
       "      Current Credit Balance  Monthly Debt  Credit Score  Credit Default  \n",
       "0                    47386.0        7914.0         749.0               0  \n",
       "1                   394972.0       18373.0         737.0               1  \n",
       "2                   308389.0       13651.0         742.0               0  \n",
       "3                    95855.0       11338.0         694.0               0  \n",
       "4                    93309.0        7180.0         719.0               0  \n",
       "...                      ...           ...           ...             ...  \n",
       "7495                 73492.0        1900.0         697.0               0  \n",
       "7496                456399.0       12783.0        7410.0               1  \n",
       "7497                477812.0       12479.0         748.0               0  \n",
       "7498                476064.0       37118.0           NaN               0  \n",
       "7499                288192.0        9061.0           NaN               0  \n",
       "\n",
       "[7500 rows x 17 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработаем данные\n",
    "\n",
    "df_work = df.copy()\n",
    "\n",
    "d={}\n",
    "for i in df_work['Years in current job'].value_counts().index:\n",
    "    if i[:2]=='10':\n",
    "        d[i]=10\n",
    "        continue\n",
    "    if i[0]=='<':\n",
    "        d[i]=0\n",
    "        continue    \n",
    "df_work['Years in current job'] = df_work['Years in current job'].map(d) \n",
    "\n",
    "\n",
    "df_work.loc[df_work['Maximum Open Credit']>7000000,'Maximum Open Credit']=7000000\n",
    "\n",
    "df_work.fillna(999,inplace=True)\n",
    "\n",
    "target_col = ['Credit Default']\n",
    "categorical_features=['Home Ownership','Tax Liens','Purpose','Term']\n",
    "discrete_feature = ['Years in current job','Number of Open Accounts',\\\n",
    "                    'Years of Credit History','Number of Credit Problems',\\\n",
    "                   'Months since last delinquent','Bankruptcies','Credit Score']\n",
    "continuous_feature = ['Annual Income','Maximum Open Credit','Current Loan Amount',\\\n",
    "                      'Current Credit Balance','Monthly Debt']\n",
    "\n",
    "target = 'Credit Default'\n",
    "\n",
    "for i in categorical_features:\n",
    "    d = enc_target(df_work,i,target)\n",
    "    df_work[i] = df_work[i].map(d)\n",
    "    df_work[i] = df_work[[i]].fillna(0)\n",
    "\n",
    "    \n",
    "X_train =  df_work.drop('Credit Default',1 )\n",
    "y_train = df_work[target]\n",
    "# y_train= y_train.map({0:1,1:2})\n",
    "\n",
    "for i in categorical_features:\n",
    "    X_train=pd.concat([X_train,pd.get_dummies(X_train[i],prefix=i)],axis=1)\n",
    "    X_train.drop(i,1,inplace=True)\n",
    "    \n",
    "for i in continuous_feature + discrete_feature:\n",
    "    X_train[i]=StandardScaler().fit_transform(X_train[[i]])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализуем данные\n",
    "X_train= normalize(X_train.to_numpy())\n",
    "y_train= to_categorical(y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем несколько слоем при одинаковом количестве нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_level_998_2_nueron_tanh\n",
      "2_level_998_2_nueron_sigmoid\n",
      "2_level_998_2_nueron_relu\n",
      "3_level_499_499_2_nueron_tanh\n",
      "3_level_499_499_2_nueron_sigmoid\n",
      "3_level_499_499_2_nueron_relu\n",
      "5_level_251_249_249_249_2_nueron_tanh\n",
      "5_level_251_249_249_249_2_nueron_sigmoid\n",
      "5_level_251_249_249_249_2_nueron_relu\n",
      "10_level_118_110_110_110_110_110_110_110_110_2_nueron_tanh\n",
      "10_level_118_110_110_110_110_110_110_110_110_2_nueron_sigmoid\n",
      "10_level_118_110_110_110_110_110_110_110_110_2_nueron_relu\n",
      "количесвто моделей -  12\n"
     ]
    }
   ],
   "source": [
    "# Создадим 12 моделей с разным количством слоев с 1000 нейронами\n",
    "n=1000\n",
    "finish_n = y_train.shape[1]\n",
    "models = []\n",
    "input_dim = X_train.shape[1]\n",
    "hide_levels = [2,3,5,10]\n",
    "for level in hide_levels:\n",
    "    n_nueron = (n-finish_n)//(level-1)\n",
    "    lost_nueron = (n-finish_n)%(level-1)\n",
    "    if level>2:\n",
    "        levels_list = [n_nueron+lost_nueron]+[n_nueron for i in range(level-2)]+[finish_n]\n",
    "    else:\n",
    "        levels_list =[n-finish_n,finish_n]    \n",
    "    for fun in['tanh','sigmoid','relu']:\n",
    "        model_name = f'{level}_level_{\"_\".join([str(i) for i in levels_list])}_nueron_{fun}'\n",
    "        denses_list = [Dense(levels_list[0],activation=fun, input_dim=input_dim,name='1')]\n",
    "        if level>2:\n",
    "            denses_list+=[ Dense(i,activation=fun,name = str(k+2)) for k,i in enumerate(levels_list[1:-1])] \n",
    "        denses_list+=[ Dense(levels_list[-1],activation='softmax',name = str(level))]  \n",
    "        my_model = Sequential(denses_list,name =model_name )\n",
    "        models.append((my_model,my_model.get_weights()))\n",
    "        print(model_name)\n",
    "print('количесвто моделей - ',len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model[0].compile(\n",
    "          optimizer='adam',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=[keras.metrics.AUC()],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для fit\n",
    "params={'epochs':15,\n",
    "       'batch_size':None, \n",
    "       'validation_split':0.2,\n",
    "       'use_multiprocessing' : True,\n",
    "       'verbose':0} \n",
    "data = {'X_train':X_train,\n",
    "        'y_train':y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.7647, valid-score = 0.7657\n",
      "=====================================================================\n",
      "Fold: 2, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.7662, valid-score = 0.7617\n",
      "=====================================================================\n",
      "Fold: 3, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.7664, valid-score = 0.7599\n",
      "=====================================================================\n",
      "Fold: 4, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.7657, valid-score = 0.7623\n",
      "=====================================================================\n",
      "Fold: 5, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.7701, valid-score = 0.7513\n",
      "=====================================================================\n",
      "CV-results train: 0.7666 +/- 0.002\n",
      "CV-results valid: 0.7602 +/- 0.005\n",
      "OOF-score = 0.7594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7593885421697131"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тестировать будем на кросвалидации. делим на 5 фолдоф, оцениваем по OOF-score по всей выборке\n",
    "make_cross_validation_classif_multi_n(X_train, y_train,models[0][0],\\\n",
    "                                roc_auc_score,cv_strategy,print_is =True,params=params)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 15min 5s\n"
     ]
    }
   ],
   "source": [
    "# Запускаем тестирование созданых моделей с разными эпохами\n",
    "result=pd.DataFrame(columns=['model','epoch','result_valid'])\n",
    "for epoh in [15,30,50,100,300]:\n",
    "    params['epochs']=epoh\n",
    "    for model in models:\n",
    "        model[0].set_weights(model[1])\n",
    "        answer = make_cross_validation_classif_multi_n(X_train, y_train,model[0],\\\n",
    "                                roc_auc_score,cv_strategy,print_is =False,params=params)[1]\n",
    "        result = result.append({'model':model[0].name,'epoch':epoh,'result_valid':answer},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epoch</th>\n",
       "      <th>result_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3_level_499_499_2_nueron_relu</td>\n",
       "      <td>100</td>\n",
       "      <td>0.877889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3_level_499_499_2_nueron_relu</td>\n",
       "      <td>50</td>\n",
       "      <td>0.873823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3_level_499_499_2_nueron_relu</td>\n",
       "      <td>300</td>\n",
       "      <td>0.870232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_relu</td>\n",
       "      <td>100</td>\n",
       "      <td>0.869054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_relu</td>\n",
       "      <td>300</td>\n",
       "      <td>0.868454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2_level_998_2_nueron_relu</td>\n",
       "      <td>300</td>\n",
       "      <td>0.865900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3_level_499_499_2_nueron_relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0.864336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_relu</td>\n",
       "      <td>50</td>\n",
       "      <td>0.862729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0.861573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.859754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.856455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2_level_998_2_nueron_relu</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_relu</td>\n",
       "      <td>15</td>\n",
       "      <td>0.845055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3_level_499_499_2_nueron_relu</td>\n",
       "      <td>15</td>\n",
       "      <td>0.844189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.839691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2_level_998_2_nueron_relu</td>\n",
       "      <td>50</td>\n",
       "      <td>0.830366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.823371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_level_998_2_nueron_relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0.811772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_tanh</td>\n",
       "      <td>300</td>\n",
       "      <td>0.804078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_level_998_2_nueron_relu</td>\n",
       "      <td>15</td>\n",
       "      <td>0.803297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3_level_499_499_2_nueron_tanh</td>\n",
       "      <td>300</td>\n",
       "      <td>0.797619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_tanh</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3_level_499_499_2_nueron_tanh</td>\n",
       "      <td>100</td>\n",
       "      <td>0.770338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3_level_499_499_2_nueron_sigmoid</td>\n",
       "      <td>300</td>\n",
       "      <td>0.769846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3_level_499_499_2_nueron_tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>0.767964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2_level_998_2_nueron_sigmoid</td>\n",
       "      <td>300</td>\n",
       "      <td>0.767205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_sigmoid</td>\n",
       "      <td>300</td>\n",
       "      <td>0.764889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.764245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2_level_998_2_nueron_tanh</td>\n",
       "      <td>300</td>\n",
       "      <td>0.763879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3_level_499_499_2_nueron_sigmoid</td>\n",
       "      <td>30</td>\n",
       "      <td>0.763441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_sigmoid</td>\n",
       "      <td>15</td>\n",
       "      <td>0.762913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2_level_998_2_nueron_tanh</td>\n",
       "      <td>100</td>\n",
       "      <td>0.762555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3_level_499_499_2_nueron_sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.762366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_level_499_499_2_nueron_sigmoid</td>\n",
       "      <td>15</td>\n",
       "      <td>0.761747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3_level_499_499_2_nueron_tanh</td>\n",
       "      <td>30</td>\n",
       "      <td>0.761048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2_level_998_2_nueron_sigmoid</td>\n",
       "      <td>50</td>\n",
       "      <td>0.760462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_level_998_2_nueron_tanh</td>\n",
       "      <td>15</td>\n",
       "      <td>0.760221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2_level_998_2_nueron_tanh</td>\n",
       "      <td>30</td>\n",
       "      <td>0.759705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.759622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2_level_998_2_nueron_tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>0.758780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_tanh</td>\n",
       "      <td>15</td>\n",
       "      <td>0.758638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3_level_499_499_2_nueron_sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.757862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.756785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2_level_998_2_nueron_sigmoid</td>\n",
       "      <td>30</td>\n",
       "      <td>0.756702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_level_499_499_2_nueron_tanh</td>\n",
       "      <td>15</td>\n",
       "      <td>0.756033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_tanh</td>\n",
       "      <td>30</td>\n",
       "      <td>0.754618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2_level_998_2_nueron_sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>0.754110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_level_998_2_nueron_sigmoid</td>\n",
       "      <td>15</td>\n",
       "      <td>0.750853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_sigmoid</td>\n",
       "      <td>30</td>\n",
       "      <td>0.750726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5_level_251_249_249_249_2_nueron_tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>0.750359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.745322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.670608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.505635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.503507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.498816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.494457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10_level_118_110_110_110_110_110_110_110_110_2...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.490907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model epoch  result_valid\n",
       "41                      3_level_499_499_2_nueron_relu   100      0.877889\n",
       "29                      3_level_499_499_2_nueron_relu    50      0.873823\n",
       "53                      3_level_499_499_2_nueron_relu   300      0.870232\n",
       "44              5_level_251_249_249_249_2_nueron_relu   100      0.869054\n",
       "56              5_level_251_249_249_249_2_nueron_relu   300      0.868454\n",
       "50                          2_level_998_2_nueron_relu   300      0.865900\n",
       "17                      3_level_499_499_2_nueron_relu    30      0.864336\n",
       "32              5_level_251_249_249_249_2_nueron_relu    50      0.862729\n",
       "20              5_level_251_249_249_249_2_nueron_relu    30      0.861573\n",
       "47  10_level_118_110_110_110_110_110_110_110_110_2...   100      0.861112\n",
       "59  10_level_118_110_110_110_110_110_110_110_110_2...   300      0.859754\n",
       "35  10_level_118_110_110_110_110_110_110_110_110_2...    50      0.856455\n",
       "38                          2_level_998_2_nueron_relu   100      0.850522\n",
       "8               5_level_251_249_249_249_2_nueron_relu    15      0.845055\n",
       "5                       3_level_499_499_2_nueron_relu    15      0.844189\n",
       "23  10_level_118_110_110_110_110_110_110_110_110_2...    30      0.839691\n",
       "26                          2_level_998_2_nueron_relu    50      0.830366\n",
       "57  10_level_118_110_110_110_110_110_110_110_110_2...   300      0.823371\n",
       "11  10_level_118_110_110_110_110_110_110_110_110_2...    15      0.821101\n",
       "14                          2_level_998_2_nueron_relu    30      0.811772\n",
       "54              5_level_251_249_249_249_2_nueron_tanh   300      0.804078\n",
       "2                           2_level_998_2_nueron_relu    15      0.803297\n",
       "51                      3_level_499_499_2_nueron_tanh   300      0.797619\n",
       "42              5_level_251_249_249_249_2_nueron_tanh   100      0.782737\n",
       "39                      3_level_499_499_2_nueron_tanh   100      0.770338\n",
       "52                   3_level_499_499_2_nueron_sigmoid   300      0.769846\n",
       "27                      3_level_499_499_2_nueron_tanh    50      0.767964\n",
       "49                       2_level_998_2_nueron_sigmoid   300      0.767205\n",
       "55           5_level_251_249_249_249_2_nueron_sigmoid   300      0.764889\n",
       "31           5_level_251_249_249_249_2_nueron_sigmoid    50      0.764245\n",
       "48                          2_level_998_2_nueron_tanh   300      0.763879\n",
       "16                   3_level_499_499_2_nueron_sigmoid    30      0.763441\n",
       "7            5_level_251_249_249_249_2_nueron_sigmoid    15      0.762913\n",
       "36                          2_level_998_2_nueron_tanh   100      0.762555\n",
       "28                   3_level_499_499_2_nueron_sigmoid    50      0.762366\n",
       "4                    3_level_499_499_2_nueron_sigmoid    15      0.761747\n",
       "15                      3_level_499_499_2_nueron_tanh    30      0.761048\n",
       "25                       2_level_998_2_nueron_sigmoid    50      0.760462\n",
       "0                           2_level_998_2_nueron_tanh    15      0.760221\n",
       "12                          2_level_998_2_nueron_tanh    30      0.759705\n",
       "9   10_level_118_110_110_110_110_110_110_110_110_2...    15      0.759622\n",
       "43           5_level_251_249_249_249_2_nueron_sigmoid   100      0.759125\n",
       "24                          2_level_998_2_nueron_tanh    50      0.758780\n",
       "6               5_level_251_249_249_249_2_nueron_tanh    15      0.758638\n",
       "40                   3_level_499_499_2_nueron_sigmoid   100      0.757862\n",
       "33  10_level_118_110_110_110_110_110_110_110_110_2...    50      0.756785\n",
       "13                       2_level_998_2_nueron_sigmoid    30      0.756702\n",
       "3                       3_level_499_499_2_nueron_tanh    15      0.756033\n",
       "18              5_level_251_249_249_249_2_nueron_tanh    30      0.754618\n",
       "37                       2_level_998_2_nueron_sigmoid   100      0.754110\n",
       "1                        2_level_998_2_nueron_sigmoid    15      0.750853\n",
       "19           5_level_251_249_249_249_2_nueron_sigmoid    30      0.750726\n",
       "30              5_level_251_249_249_249_2_nueron_tanh    50      0.750359\n",
       "45  10_level_118_110_110_110_110_110_110_110_110_2...   100      0.745322\n",
       "21  10_level_118_110_110_110_110_110_110_110_110_2...    30      0.670608\n",
       "22  10_level_118_110_110_110_110_110_110_110_110_2...    30      0.505635\n",
       "10  10_level_118_110_110_110_110_110_110_110_110_2...    15      0.503507\n",
       "34  10_level_118_110_110_110_110_110_110_110_110_2...    50      0.498816\n",
       "46  10_level_118_110_110_110_110_110_110_110_110_2...   100      0.494457\n",
       "58  10_level_118_110_110_110_110_110_110_110_110_2...   300      0.490907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('result_valid',ascending=False,inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем двухслойные модели с разным количеством нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 33min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N=1000\n",
    "result2=pd.DataFrame()\n",
    "for n_nueron in range(10,N+1,50):\n",
    "    for fun in['tanh','sigmoid','relu']:\n",
    "        dens =[ Dense(n_nueron,input_dim=X_train.shape[1],activation=fun,name= '1'),\n",
    "                Dense(y_train.shape[1],activation='softmax',name='exit')]\n",
    "        model_level_2 = Sequential(dens, name=f'{n_nueron}_{fun}')\n",
    "        model_level_2.compile(optimizer='adam',\n",
    "                              loss='categorical_crossentropy',\n",
    "                               metrics=[keras.metrics.AUC()])\n",
    "        a = model_level_2.get_weights()   \n",
    "                \n",
    "        for epoh in [15,30,100]:\n",
    "            model_level_2.set_weights(a)    \n",
    "            params['epochs']=epoh\n",
    "            answer = make_cross_validation_classif_multi_n(X_train, y_train,model_level_2,\\\n",
    "                                roc_auc_score,cv_strategy,print_is =False,params=params)[1]\n",
    "            result2 = result2.append({'model':model_level_2.name,'epoch':epoh,'result_valid':answer},ignore_index=True)    \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>model</th>\n",
       "      <th>result_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>100.0</td>\n",
       "      <td>910_relu</td>\n",
       "      <td>0.852031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>100.0</td>\n",
       "      <td>960_relu</td>\n",
       "      <td>0.848617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>100.0</td>\n",
       "      <td>810_relu</td>\n",
       "      <td>0.846014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>100.0</td>\n",
       "      <td>860_relu</td>\n",
       "      <td>0.845380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>100.0</td>\n",
       "      <td>760_relu</td>\n",
       "      <td>0.843755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>30.0</td>\n",
       "      <td>660_sigmoid</td>\n",
       "      <td>0.747899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>30.0</td>\n",
       "      <td>860_sigmoid</td>\n",
       "      <td>0.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>15.0</td>\n",
       "      <td>860_sigmoid</td>\n",
       "      <td>0.745410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>15.0</td>\n",
       "      <td>760_sigmoid</td>\n",
       "      <td>0.745255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>15.0</td>\n",
       "      <td>460_sigmoid</td>\n",
       "      <td>0.744898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch        model  result_valid\n",
       "170  100.0     910_relu      0.852031\n",
       "179  100.0     960_relu      0.848617\n",
       "152  100.0     810_relu      0.846014\n",
       "161  100.0     860_relu      0.845380\n",
       "143  100.0     760_relu      0.843755\n",
       "..     ...          ...           ...\n",
       "121   30.0  660_sigmoid      0.747899\n",
       "157   30.0  860_sigmoid      0.746000\n",
       "156   15.0  860_sigmoid      0.745410\n",
       "138   15.0  760_sigmoid      0.745255\n",
       "84    15.0  460_sigmoid      0.744898\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.sort_values('result_valid',ascending=False,inplace=True)\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем с разными оптимизаторам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result=pd.DataFrame()\n",
    "for fun in['sigmoid','relu']:\n",
    "    dens =[ Dense(910,input_dim=X_train.shape[1],activation=fun,name= '1'),\n",
    "            Dense(y_train.shape[1],activation='softmax',name='exit')]\n",
    "    model = Sequential(dens, name=f'960_{fun}')\n",
    "    a = model.get_weights()\n",
    "    for epoh in [15,30,100]:\n",
    "        params['epochs'] = epoh\n",
    "        for opt in [keras.optimizers.RMSprop(),keras.optimizers.SGD(),keras.optimizers.Nadam()]:       \n",
    "                model.compile(optimizer=opt,\n",
    "                              loss='categorical_crossentropy',\n",
    "                              metrics=[keras.metrics.AUC()])\n",
    "                model.set_weights(a) \n",
    "                answer = make_cross_validation_classif_multi_n(X_train, y_train,model,\\\n",
    "                                roc_auc_score,cv_strategy,print_is =False,params=params)[1]\n",
    "                ful_result = ful_result.append({'model':model.name,\\\n",
    "                                             'epoch':epoh,\n",
    "                                              'opt':opt,  \n",
    "                                              'result_valid':answer},ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result.sort_values('result_valid',ascending=False,inplace=True)\n",
    "ful_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем 10 слойную сеть с разными оптимизаторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result2=pd.DataFrame()\n",
    "for fun in['sigmoid','relu']:\n",
    "    dens =[ Dense(100,input_dim=X_train.shape[1],activation=fun,name= '1'),\n",
    "            Dense(100,activation=fun,name= '2'),\n",
    "           Dense(100,activation=fun,name= '3'),\n",
    "           Dense(100,activation=fun,name= '4'),\n",
    "           Dense(100,activation=fun,name= '5'),\n",
    "           Dense(100,activation=fun,name= '6'),\n",
    "           Dense(100,activation=fun,name= '7'),\n",
    "           Dense(100,activation=fun,name= '8'),\n",
    "           Dense(100,activation=fun,name= '9'),\n",
    "            Dense(y_train.shape[1],activation='softmax',name='exit')]\n",
    "    model = Sequential(dens, name=f'10_100_{fun}')\n",
    "    a = model.get_weights()\n",
    "    for epoh in [15,30,100]:\n",
    "        params['epochs'] = epoh\n",
    "        for opt in [keras.optimizers.RMSprop(),keras.optimizers.SGD(),keras.optimizers.Nadam()]:       \n",
    "                model.compile(optimizer=opt,\n",
    "                              loss='categorical_crossentropy',\n",
    "                              metrics=[keras.metrics.AUC()])\n",
    "                model.set_weights(a) \n",
    "                answer = make_cross_validation_classif_multi_n(X_train, y_train,model,\\\n",
    "                                roc_auc_score,cv_strategy,print_is =False,params=params)[1]\n",
    "                ful_result2 = ful_result2.append({'model':model.name,\\\n",
    "                                             'epoch':epoh,\n",
    "                                              'opt':opt,  \n",
    "                                              'result_valid':answer},ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>model</th>\n",
       "      <th>opt</th>\n",
       "      <th>result_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.nadam.Na...</td>\n",
       "      <td>0.856219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.nadam.Na...</td>\n",
       "      <td>0.855623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.nadam.Na...</td>\n",
       "      <td>0.827464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.rmsprop....</td>\n",
       "      <td>0.814790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.gradient...</td>\n",
       "      <td>0.813339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.rmsprop....</td>\n",
       "      <td>0.808881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.rmsprop....</td>\n",
       "      <td>0.789093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.gradient...</td>\n",
       "      <td>0.775781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10_100_relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.gradient...</td>\n",
       "      <td>0.769099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.rmsprop....</td>\n",
       "      <td>0.503521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.nadam.Na...</td>\n",
       "      <td>0.502373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.rmsprop....</td>\n",
       "      <td>0.502049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.rmsprop....</td>\n",
       "      <td>0.498044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.gradient...</td>\n",
       "      <td>0.496050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.nadam.Na...</td>\n",
       "      <td>0.491477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.nadam.Na...</td>\n",
       "      <td>0.487698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.gradient...</td>\n",
       "      <td>0.485418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>10_100_sigmoid</td>\n",
       "      <td>&lt;tensorflow.python.keras.optimizer_v2.gradient...</td>\n",
       "      <td>0.484327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch           model                                                opt  \\\n",
       "14   30.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.nadam.Na...   \n",
       "17  100.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.nadam.Na...   \n",
       "11   15.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.nadam.Na...   \n",
       "15  100.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.rmsprop....   \n",
       "16  100.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.gradient...   \n",
       "12   30.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.rmsprop....   \n",
       "9    15.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.rmsprop....   \n",
       "10   15.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.gradient...   \n",
       "13   30.0     10_100_relu  <tensorflow.python.keras.optimizer_v2.gradient...   \n",
       "3    30.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.rmsprop....   \n",
       "2    15.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.nadam.Na...   \n",
       "6   100.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.rmsprop....   \n",
       "0    15.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.rmsprop....   \n",
       "1    15.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.gradient...   \n",
       "8   100.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.nadam.Na...   \n",
       "5    30.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.nadam.Na...   \n",
       "7   100.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.gradient...   \n",
       "4    30.0  10_100_sigmoid  <tensorflow.python.keras.optimizer_v2.gradient...   \n",
       "\n",
       "    result_valid  \n",
       "14      0.856219  \n",
       "17      0.855623  \n",
       "11      0.827464  \n",
       "15      0.814790  \n",
       "16      0.813339  \n",
       "12      0.808881  \n",
       "9       0.789093  \n",
       "10      0.775781  \n",
       "13      0.769099  \n",
       "3       0.503521  \n",
       "2       0.502373  \n",
       "6       0.502049  \n",
       "0       0.498044  \n",
       "1       0.496050  \n",
       "8       0.491477  \n",
       "5       0.487698  \n",
       "7       0.485418  \n",
       "4       0.484327  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ful_result2.sort_values('result_valid',ascending=False,inplace=True)\n",
    "ful_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем 3 слойную сеть с разными оптимизаторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ful_result3=pd.DataFrame()\n",
    "for fun in['sigmoid','relu']:\n",
    "    dens =[ Dense(499,input_dim=X_train.shape[1],activation=fun,name= '1'),\n",
    "            Dense(499,activation=fun,name= '2'),\n",
    "            Dense(y_train.shape[1],activation='softmax',name='exit')]\n",
    "    model = Sequential(dens, name=f'499_499_10_{fun}')\n",
    "    a = model.get_weights()\n",
    "    for epoh in [30,100,200]:\n",
    "        params['epochs'] = epoh\n",
    "        for opt in [keras.optimizers.RMSprop(),keras.optimizers.SGD(),keras.optimizers.Nadam(),'adam']:       \n",
    "                model.compile(optimizer=opt,\n",
    "                              loss='categorical_crossentropy',\n",
    "                              metrics=[keras.metrics.AUC()])\n",
    "                model.set_weights(a) \n",
    "                answer = make_cross_validation_classif_multi_n(X_train, y_train,model,\\\n",
    "                                roc_auc_score,cv_strategy,print_is =False,params=params)[1]\n",
    "                ful_result3 = ful_result3.append({'model':model.name,\\\n",
    "                                             'epoch':epoh,\n",
    "                                              'opt':opt,  \n",
    "                                              'result_valid':answer},ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result3.sort_values('result_valid',ascending=False,inplace=True)\n",
    "ful_result3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_result3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Победитель -     , проверим его результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.8056, valid-score = 0.792\n",
      "=====================================================================\n",
      "Fold: 2, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.8058, valid-score = 0.7983\n",
      "=====================================================================\n",
      "Fold: 3, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.8054, valid-score = 0.8047\n",
      "=====================================================================\n",
      "Fold: 4, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.8065, valid-score = 0.8073\n",
      "=====================================================================\n",
      "Fold: 5, train-observations = 6000, valid-observations = 1500\n",
      "train-score = 0.8117, valid-score = 0.7827\n",
      "=====================================================================\n",
      "CV-results train: 0.807 +/- 0.002\n",
      "CV-results valid: 0.797 +/- 0.009\n",
      "OOF-score = 0.7955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7954634305247132"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['epochs'] = 15\n",
    "dens =[ Dense(960,input_dim=X_train.shape[1],activation='relu',name= '1'),\n",
    "            Dense(y_train.shape[1],activation='softmax',name='exit')]\n",
    "model = Sequential(dens, name=f'960_{fun}')\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[keras.metrics.AUC()])\n",
    "cv = make_cross_validation_classif_multi_n(X_train, y_train,models[0][0],\\\n",
    "                                roc_auc_score,cv_strategy,print_is =True,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.metrics import roc_auc_score, f1_score,r2_score,classification_report,accuracy_score,precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proba_calibration_plots(y_predicted_probs, y_true_labels):\n",
    "    preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n",
    "\n",
    "    thresholds = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for threshold in np.linspace(0.1, 0.9, 9):\n",
    "        thresholds.append(threshold)\n",
    "        precisions.append(precision_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "        recalls.append(recall_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "        f1_scores.append(f1_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "\n",
    "    scores_table = pd.DataFrame({'f1':f1_scores,\n",
    "                                 'precision':precisions,\n",
    "                                 'recall':recalls,\n",
    "                                 'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n",
    "  \n",
    "    figure = plt.figure(figsize = (15, 5))\n",
    "\n",
    "    plt1 = figure.add_subplot(121)\n",
    "    plt1.plot(thresholds, precisions, label='Precision', linewidth=4)\n",
    "    plt1.plot(thresholds, recalls, label='Recall', linewidth=4)\n",
    "    plt1.plot(thresholds, f1_scores, label='F1', linewidth=4)\n",
    "    plt1.set_ylabel('Scores')\n",
    "    plt1.set_xlabel('Probability threshold')\n",
    "    plt1.set_title('Probabilities threshold calibration')\n",
    "    plt1.legend(bbox_to_anchor=(0.25, 0.25))   \n",
    "    plt1.table(cellText = scores_table.values,\n",
    "               colLabels = scores_table.columns, \n",
    "               colLoc = 'center', cellLoc = 'center', loc = 'bottom', bbox = [0, -1.3, 1, 1])\n",
    "\n",
    "    plt2 = figure.add_subplot(122)\n",
    "    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 0][:, 0], \n",
    "              label='Another class', color='royalblue', alpha=1)\n",
    "    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 1][:, 0], \n",
    "              label='Main class', color='darkcyan', alpha=0.8)\n",
    "    plt2.set_ylabel('Number of examples')\n",
    "    plt2.set_xlabel('Probabilities')\n",
    "    plt2.set_title('Probability histogram')\n",
    "    plt2.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(pred,y_test):\n",
    "    d = {}\n",
    "    for i in np.arange(0.05,0.96,0.01):\n",
    "        z = np.where(pred < i, 0, 1)\n",
    "        d[i] = f1_score(y_test,z)\n",
    "    return sorted(d, key=d.get, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_proba_calibration_plots(res[4], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = get_best_split(res[4], target)\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=np.where(y_train_pred<0.33,0,1)\n",
    "y_test_pred = np.where(res[4]<0.33,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_report(target, y_train_pred, target, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
